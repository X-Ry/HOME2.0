---
title: 'Senior Experience Machine Learning Section 8 - Decision Tree Regression'
date: '2019-12-12 7:30am'
description: 'Senior Experience Machine Learning Section 8'
author: x-ry	

layout: post
comments: false
hidden: false
published: true 

surfaceTags: false
showDate: true
---

**Decision Tree Intuition**

CART = encapsulates 2 types of trees: Classification Trees, Regression Trees
******
<table>
	<tr>
		<th> Ok so a lot of the time if you see a decision tree thing looking like this. <br>
			(This is an example with 2 independent variables and the machine predicting 1 variable) <br>
			The diagram will be split!
 		</th>
 		<th> <img src="https://x-ry.github.io/assets/images/posts/ml/8split.png" width="450" alt="alt_text" title="image_tooltip">
 		</th>	
	</tr>
</table>
******
<table>
	<tr>
		<th> <img src="https://x-ry.github.io/assets/images/posts/ml/8split2.png" width="450" alt="alt_text" title="image_tooltip">
 		</th>
 		<th> Splits are determined by asking “does this split of data increase the amount of information we have about these points” <br> and will stop once it cannot add more information from splitting.
 		</th>	
	</tr>
</table>
******
**How is the machine going to predict using a Decision Tree?**

Let’s say the next point is x=30 y=30. It’d fall in the middle-bottom area (box), **terminal leaf**, of that decision tree. In each terminal leaf, the points have an average value. 

**R-Squared**

Evaluates how good regression is going using Sum of Squares.

R^2=1-(SS/TSS)

(used in regression) Sum of Squares → Y1 - Y(predicted line)

Total Sum of Squares → Y1 - Y(average)
